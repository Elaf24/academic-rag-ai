import streamlit as st
from langchain_openai import AzureChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
from langchain.prompts import PromptTemplate
from langchain.vectorstores import FAISS
from config.config import CONFIG

def create_optimized_conversation_chain(vectorstore: FAISS) -> any:
    """
    Create optimized conversation chain with FAISS retriever
    """
    st.info("ЁЯдЦ Setting up optimized conversation chain...")
    
    llm = AzureChatOpenAI(
        azure_endpoint=CONFIG["AZURE_OPENAI_ENDPOINT"],
        api_key=CONFIG["AZURE_OPENAI_API_KEY"],
        azure_deployment=CONFIG["AZURE_OPENAI_DEPLOYMENT_NAME"],
        openai_api_version=CONFIG["OPENAI_CHAT_API_VERSION"],
        temperature=0.2,
        max_tokens=3000,
        top_p=0.85,
        frequency_penalty=0.0,
        presence_penalty=0.0
    )
    
    memory = ConversationBufferMemory(
        memory_key='chat_history',
        return_messages=True,
        output_key='answer'
    )
    
    retriever = vectorstore.as_retriever(
        search_type="mmr",
        search_kwargs={
            "k": 50,
            "fetch_k": 100, 
            "lambda_mult": 0.6 
        }
    )

    custom_template = """
    You are an expert assistant for analyzing Bengali documents. Answer questions based on the provided context.

    Context from documents:
    {context}

    Conversation History:
    {chat_history}

    Question: {question}

    Instructions:
    ржЖржкржирж╛рж░ ржЬрзНржЮрж╛ржи  рж╢рзБржзрзБ ржПржЗ ржбржХрзБржорзЗржирзНржЯ ржП рж╢рж┐ржорж╛рж╣ржмржжрзНржз ,ржПрж░ ржмрж╛рж╣рж┐рж░рзЗ ржЙрждрзНрждрж░ ржжрзЗрзЯрж╛ ржпрж╛ржмрзЗ ржирж╛ ред 
   ржнрзВржорж┐ржХрж╛: ржЖржкржирж┐ ржПржХржЬржи ржжржХрзНрж╖ ржбржХрзБржорзЗржирзНржЯ ржмрж┐рж╢рзНрж▓рзЗрж╖ржХред ржЖржкржирж╛рж░ ржХрж╛ржЬ рж╣рж▓рзЛ ржкрзНрж░ржжрждрзНржд ржбржХрзБржорзЗржирзНржЯ ржерзЗржХрзЗ рж╕ржмржЪрзЗржпрж╝рзЗ рж╕ржарж┐ржХ ржУ ржкрзВрж░рзНржгрж╛ржЩрзНржЧ ржЙрждрзНрждрж░ ржЦрзБржБржЬрзЗ ржмрзЗрж░ ржХрж░рж╛ред

ржирж┐рж░рзНржжрзЗрж╢рж╛ржмрж▓рзА:
1. ржЧржнрзАрж░ржнрж╛ржмрзЗ ржЕржирзБрж╕ржирзНржзрж╛ржи ржХрж░рзБржи:
   - ржкрзНрж░рж╢рзНржирзЗрж░ ржкрзНрж░рждрж┐ржЯрж┐ рж╢ржмрзНржж/ржкрзНрж░рж╕ржЩрзНржЧ ржЦрзБржБржЬрзБржи (ржпрзЗржоржи: "ржЕржирзБржкржорзЗрж░ ржорж╛ржорж╛", "ржпрж╛ржУржпрж╝рж╛рж░ рж╕рзНржерж╛ржи")
   - рж╕ржорж╕рзНржд ржкрзНрж░рж╛рж╕ржЩрзНржЧрж┐ржХ ржЕржВрж╢ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи (ржкрзГрж╖рзНржарж╛, ржЕржирзБржЪрзНржЫрзЗржж, ржкрж╛ржжржЯрзАржХрж╛)
   - рзи-рзй ржмрж╛рж░ ржбржХрзБржорзЗржирзНржЯ ржЪрзЗржХ ржХрж░рзБржи ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг ржкрзНрж░рж╢рзНржирзЗрж░ ржЬржирзНржп
   - ржПржорж╕рж┐ржХрж┐ржЙ/ржЕржкрж╢ржи рж╣рзНржпрж╛ржирзНржбрж▓рж┐ржВ: 
        # - ржпржжрж┐ ржбржХрзБржорзЗржирзНржЯрзЗрж░ ржХрзЛржерж╛ржУ ржПржорж╕рж┐ржХрж┐ржЙ ржкрзНрж░рж╢рзНржи ржмрж╛ ржЙрждрзНрждрж░ ржЕржкрж╢ржи ржкрж╛ржУржпрж╝рж╛ ржпрж╛ржпрж╝:
        #     рзз. рж╕ржорж╕рзНржд ржЕржкрж╢ржи ржХрзНрж░рж╕-ржнрж╛рж▓рж┐ржбрзЗрж╢ржи ржХрж░рзБржи (ржмрж┐ржнрж┐ржирзНржи ржЬрж╛ржпрж╝ржЧрж╛ржпрж╝ ржЪрзЗржХ ржХрж░рзБржи)
        #     рзи. ржХрзЛржи ржЙрждрзНрждрж░ ржнрж┐ржирзНржи рж╣рж▓рзЗ ржмржЗржпрж╝рзЗрж░ ржорзВрж▓ ржЕржВрж╢рзЗрж░ ржЙрждрзНрждрж░ржЯрж┐ ржирж┐ржи
        #     рзй. ржЕржкрж╢ржи ржПржмржВ ржмржЗржпрж╝рзЗрж░ ржоржзрзНржпрзЗ ржкрж╛рж░рзНржержХрзНржп ржерж╛ржХрж▓рзЗ: "ржмржЗржпрж╝рзЗрж░ ржорзВрж▓ ржЕржВрж╢ ржЕржирзБржпрж╛ржпрж╝рзА рж╕ржарж┐ржХ ржЙрждрзНрждрж░: [answer]"

2. ржЙрждрзНрждрж░рзЗрж░ ржирзАрждрж┐:
   - ржЙрждрзНрждрж░ ржжрзЗржмрзЗржи рж╢рзБржзрзБржорж╛рждрзНрж░ ржбржХрзБржорзЗржирзНржЯрзЗ ржпрж╛ ржЖржЫрзЗ рждрж╛ ржерзЗржХрзЗ
   - ржбржХрзБржорзЗржирзНржЯрзЗ ржирж╛ ржкрзЗрж▓рзЗ: "ржПржЗ рждржерзНржп ржкрзНрж░ржжрждрзНржд ржбржХрзБржорзЗржирзНржЯрзЗ ржкрж╛ржУржпрж╝рж╛ ржпрж╛ржпрж╝ржирж┐"
   -ржпржжрж┐ ржкрж░рзНржпрж╛ржкрзНржд рждржерзНржп ржирж╛ ржерж╛ржХрзЗ, рждрж╛рж╣рж▓рзЗ ржЖрж░ржУ ржкрзНрж░рж╛рж╕ржЩрзНржЧрж┐ржХ ржкрзНрж░рзЗржХрзНрж╖рж╛ржкржЯ ржмрж╛ рждржерзНржп ржЪрж╛ржУред
   - ржкрзНрж░рж╢рзНржирзЗрж░ ржнрж╛рж╖рж╛ржпрж╝ ржЙрждрзНрждрж░ ржжрж┐ржи (ржмрж╛ржВрж▓рж╛/ржЗржВрж░рзЗржЬрж┐)

3. ржмрж╛ржВрж▓рж╛ ржкрзНрж░рж╢рзНржирзЗрж░ ржмрж┐рж╢рзЗрж╖ ржирж┐рж░рзНржжрзЗрж╢ржирж╛:
   - ржмрж╛ржВрж▓рж╛ ржмрж╛ржирж╛ржи ржУ ржпрзБржХрзНрждрж╛ржХрзНрж╖рж░ рж╕ржарж┐ржХ рж░рж╛ржЦрзБржи (ржпрзЗржоржи: "ржЧрзНрж░рж╛ржорзЗ" ржирж╛ "ржЧрзЗрж░рж╛ржорзЗ")
   - рж╕рж░рзНржмржжрж╛ ржорзВрж▓ ржЙржжрзНржзрзГрждрж┐ ржжрж┐ржи: "ржкрж╛ржарзНржп  ржмржЗ ржП  ржмрж▓рж╛ рж╣ржпрж╝рзЗржЫрзЗ: '......'"
   - рж╕ржорзНржорж╛ржирж╕рзВржЪржХ ржнрж╛рж╖рж╛ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи (ржЖржкржирж┐, рждрж┐ржирж┐, рждрж╛ржБрж░рж╛)

4. ржХржерзЛржкржХржержирзЗрж░ ржкрзНрж░ржмрж╛рж╣:
   - ржЖржЧрзЗрж░ ржкрзНрж░рж╢рзНржирзЗрж░ ржкрзНрж░рж╕ржЩрзНржЧ ржоржирзЗ рж░рж╛ржЦрзБржи (ржпрзЗржоржи: "ржЕржирзБржкржорзЗрж░ ржорж╛ржорж╛" тЖТ "рждрж┐ржирж┐")
   - рж╕рзНржмрж╛ржнрж╛ржмрж┐ржХржнрж╛ржмрзЗ ржЙрждрзНрждрж░ ржжрж┐ржи ржпрзЗржи ржорж╛ржирзБрж╖рзЗрж░ рж╕рж╛ржерзЗ ржХржерж╛ ржмрж▓ржЫрзЗржи

5. ржЬржЯрж┐рж▓ ржкрзНрж░рж╢рзНржи ржкрж░рж┐ржЪрж╛рж▓ржирж╛:
   - ржПржХрж╛ржзрж┐ржХ рж╕ржорзНржнрж╛ржмржирж╛ ржерж╛ржХрж▓рзЗ: "ржЖржкржирж┐ ржХрж┐ ржмрзЛржЭрж╛рждрзЗ ржЪрзЗржпрж╝рзЗржЫрзЗржи [option 1] ржирж╛ [option 2]?"
   - ржмрж┐рж░рзЛржзржкрзВрж░рзНржг рждржерзНржп ржерж╛ржХрж▓рзЗ: "ржжрзБржЗ ржЬрж╛ржпрж╝ржЧрж╛ржпрж╝ ржнрж┐ржирзНржи рждржерзНржп ржЖржЫрзЗ: [source1] ржП ржмрж▓рж╛ рж╣ржпрж╝рзЗржЫрзЗ... ржЖржмрж╛рж░ [source2] рждрзЗ..."

    Answer:
    """
    
    prompt = PromptTemplate(
        input_variables=["context", "chat_history", "question"],
        template=custom_template
    )
    
    conversation_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=retriever,
        memory=memory,
        return_source_documents=True,
        verbose=False,
        combine_docs_chain_kwargs={"prompt": prompt}
    )
    
    st.success("тЬЕ Optimized conversation chain with FAISS ready!")
    return conversation_chain